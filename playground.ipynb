{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import timedelta\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qualifying_position: 149\n",
      "qualifying_time: 298\n",
      "sprint_qualifying_position: 3621\n",
      "sprint_qualifying_time: 3631\n",
      "fp_pos_1: 194\n",
      "fp_time_1: 321\n",
      "fp_pos_2: 258\n",
      "fp_time_2: 325\n",
      "fp_pos_3: 343\n",
      "fp_time_3: 431\n",
      "sprint_fl_pos: 3643\n",
      "sprint_fl_time: 3643\n",
      "sprint_laps: 3620\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sprint_pos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/573/lib/python3.10/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/573/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/573/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sprint_pos'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/mauricechiu/PP-ProgrammingProjects/PURG-PurdueGradProjects/573cs/f1/playground.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mauricechiu/PP-ProgrammingProjects/PURG-PurdueGradProjects/573cs/f1/playground.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msprint_fl_time: \u001b[39m\u001b[39m{\u001b[39;00mfinal_df[\u001b[39m'\u001b[39m\u001b[39msprint_fl_time\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39msum()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mauricechiu/PP-ProgrammingProjects/PURG-PurdueGradProjects/573cs/f1/playground.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msprint_laps: \u001b[39m\u001b[39m{\u001b[39;00mfinal_df[\u001b[39m'\u001b[39m\u001b[39msprint_laps\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39msum()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mauricechiu/PP-ProgrammingProjects/PURG-PurdueGradProjects/573cs/f1/playground.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msprint_pos: \u001b[39m\u001b[39m{\u001b[39;00mfinal_df[\u001b[39m'\u001b[39;49m\u001b[39msprint_pos\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39msum()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mauricechiu/PP-ProgrammingProjects/PURG-PurdueGradProjects/573cs/f1/playground.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msprint_time: \u001b[39m\u001b[39m{\u001b[39;00mfinal_df[\u001b[39m'\u001b[39m\u001b[39msprint_time\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39msum()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mauricechiu/PP-ProgrammingProjects/PURG-PurdueGradProjects/573cs/f1/playground.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfl_pos: \u001b[39m\u001b[39m{\u001b[39;00mfinal_df[\u001b[39m'\u001b[39m\u001b[39mfl_pos\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39msum()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/573/lib/python3.10/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/573/lib/python3.10/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sprint_pos'"
     ]
    }
   ],
   "source": [
    "final_df = pd.read_csv('./data/final_df.csv')\n",
    "\n",
    "print(f\"qualifying_position: {final_df['qualifying_position'].isnull().sum()}\")\n",
    "print(f\"qualifying_time: {final_df['qualifying_time'].isnull().sum()}\")\n",
    "print(f\"sprint_qualifying_position: {final_df['sprint_qualifying_position'].isnull().sum()}\")\n",
    "print(f\"sprint_qualifying_time: {final_df['sprint_qualifying_time'].isnull().sum()}\")\n",
    "print(f\"fp_pos_1: {final_df['fp_pos_1'].isnull().sum()}\")\n",
    "print(f\"fp_time_1: {final_df['fp_time_1'].isnull().sum()}\")\n",
    "print(f\"fp_pos_2: {final_df['fp_pos_2'].isnull().sum()}\")\n",
    "print(f\"fp_time_2: {final_df['fp_time_2'].isnull().sum()}\")\n",
    "print(f\"fp_pos_3: {final_df['fp_pos_3'].isnull().sum()}\")\n",
    "print(f\"fp_time_3: {final_df['fp_time_3'].isnull().sum()}\")\n",
    "print(f\"sprint_fl_pos: {final_df['sprint_fl_pos'].isnull().sum()}\")\n",
    "print(f\"sprint_fl_time: {final_df['sprint_fl_time'].isnull().sum()}\")\n",
    "print(f\"sprint_laps: {final_df['sprint_laps'].isnull().sum()}\")\n",
    "print(f\"sprint_position: {final_df['sprint_position'].isnull().sum()}\")\n",
    "print(f\"sprint_time: {final_df['sprint_time'].isnull().sum()}\")\n",
    "print(f\"fl_pos: {final_df['fl_pos'].isnull().sum()}\")\n",
    "print(f\"fl_time: {final_df['fl_time'].isnull().sum()}\")\n",
    "# final_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_cleanup(input_string):\n",
    "    result_string = np.nan\n",
    "    try:\n",
    "        groups = input_string.split(\" \")\n",
    "        if len(groups) == 1:\n",
    "            result_string = groups[0]\n",
    "        if len(groups) == 2:\n",
    "            result_string = groups[1]\n",
    "        if len(groups) == 3:\n",
    "            result_string = groups[2]\n",
    "    except:\n",
    "        print(\"time cleanup error\")\n",
    "    return result_string\n",
    "\n",
    "def convert_time(time_str):\n",
    "    rounded = np.nan\n",
    "    try:\n",
    "        # print(time_str)\n",
    "        # Splitting the time into minutes and seconds\n",
    "\n",
    "        # minutes, seconds = time_str.split(\"'\")\n",
    "        time_strings = time_str.split(\"'\")\n",
    "        if len(time_strings) == 1:\n",
    "            hours = 0\n",
    "            minutes = 0\n",
    "            seconds = time_strings[0]\n",
    "        elif len(time_strings) == 2:\n",
    "            hours = 0\n",
    "            minutes = time_strings[0]\n",
    "            seconds = time_strings[1]\n",
    "        elif len(time_strings) == 3:\n",
    "            hours = time_strings[0]\n",
    "            minutes = time_strings[1]\n",
    "            seconds = time_strings[2]\n",
    "\n",
    "        total_seconds = int(hours) * 60 * 60 + int(minutes) * 60 + float(seconds)\n",
    "        # Converting total seconds to hh:mm:ss format\n",
    "        formatted_time = timedelta(seconds=total_seconds)\n",
    "        # Formatting the output to round milliseconds to 3 decimal places\n",
    "        rounded = '{:02}:{:02}:{:06.3f}'.format(int(formatted_time.total_seconds() // 3600),\n",
    "                                            int(formatted_time.total_seconds() % 3600 // 60),\n",
    "                                            formatted_time.total_seconds() % 60)\n",
    "        # print(rounded)\n",
    "    except:\n",
    "        print(\"time convert error\")\n",
    "    # print(rounded)\n",
    "    return rounded\n",
    "\n",
    "def time_to_milliseconds(time_str):\n",
    "    milliseconds = np.nan\n",
    "    try:\n",
    "        parts = time_str.split(':')\n",
    "        milliseconds = 0\n",
    "\n",
    "        if len(parts) == 3:\n",
    "            # Format is hours:minutes:seconds.milliseconds\n",
    "            hours, minutes, seconds = parts\n",
    "            milliseconds += int(hours) * 3600000  # Convert hours to milliseconds\n",
    "            milliseconds += int(minutes) * 60000  # Convert minutes to milliseconds\n",
    "        elif len(parts) == 2:\n",
    "            # Format is minutes:seconds.milliseconds\n",
    "            minutes, seconds = parts\n",
    "            milliseconds += int(minutes) * 60000  # Convert minutes to milliseconds\n",
    "        else:\n",
    "            raise ValueError(\"Invalid time format\")\n",
    "\n",
    "        # Splitting seconds and milliseconds and converting\n",
    "        seconds, msec = seconds.split('.')\n",
    "        milliseconds += int(seconds) * 1000  # Convert seconds to milliseconds\n",
    "        milliseconds += int(msec)  # Add milliseconds\n",
    "    except:\n",
    "        print(\"time to milli error\")\n",
    "    return milliseconds\n",
    "\n",
    "def remove_space(input):\n",
    "    result = str(input)\n",
    "    result = result.replace(\" \", \"\")\n",
    "    return result\n",
    "\n",
    "# def to_int(input):\n",
    "#     return int(input)\n",
    "def to_int(input):\n",
    "    result = np.nan\n",
    "    try:\n",
    "        result = int(input)\n",
    "    except:\n",
    "        print(\"error when casting to int\")\n",
    "    return result\n",
    "\n",
    "def get_tyre_type(input):\n",
    "    return input.split(\":\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.autosport.com/f1/results/2016/british-gp-488120/\"\n",
    "\n",
    "season = 2016\n",
    "round = 10\n",
    "race = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    qp_url = f\"{url}?st=GRID\"\n",
    "    print(qp_url)\n",
    "    # Get driver names\n",
    "    r = requests.get(qp_url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    driver_names = []\n",
    "    class_name = \"ms-link info-wrapper\"\n",
    "    for page in soup.find_all('a', attrs = {'class':class_name}):\n",
    "        link = page.get('href')\n",
    "        name = link.split(\"/\")[2]\n",
    "        name = name.replace(\"-\", \" \")\n",
    "        name = name.lower()\n",
    "        driver_names.append(name)\n",
    "    name_df = pd.DataFrame({\"driver_name\": driver_names})\n",
    "    table_df = pd.DataFrame()\n",
    "    try: \n",
    "        table_df = pd.read_html(qp_url)\n",
    "        table_df = table_df[0]\n",
    "        table_df.columns = table_df.columns.droplevel(0)\n",
    "        table_df = table_df[['Cla', 'Time']]\n",
    "        table_df['Cla'] = table_df['Cla'].apply(to_int)\n",
    "        table_df['Time'] = table_df['Time'].apply(time_cleanup)\n",
    "        table_df['Time'] = table_df['Time'].apply(convert_time)\n",
    "        table_df['Time'] = table_df['Time'].apply(time_to_milliseconds)\n",
    "    except:\n",
    "        print(\"no data found under tab GRID, try GRID1 for time and GRID2 for position\")\n",
    "        try:\n",
    "            qp_time_url = f\"{url}?st=GRID1\"\n",
    "            table_time_df = pd.read_html(qp_time_url)\n",
    "            table_time_df = table_time_df[0]\n",
    "            table_time_df.columns = table_time_df.columns.droplevel(0)\n",
    "            table_time_df = table_time_df[['Time']]\n",
    "            table_time_df['Time'] = table_time_df['Time'].apply(time_cleanup)\n",
    "            table_time_df['Time'] = table_time_df['Time'].apply(convert_time)\n",
    "            table_time_df['Time'] = table_time_df['Time'].apply(time_to_milliseconds)\n",
    "\n",
    "        except:\n",
    "            print(\"no Time data found under tab GRID1\")\n",
    "\n",
    "        try:\n",
    "            qp_position_url = f\"{url}?st=GRID2\"\n",
    "            table_pos_df = pd.read_html(qp_position_url)\n",
    "            table_pos_df = table_pos_df[0]\n",
    "            table_pos_df.columns = table_pos_df.columns.droplevel(0)\n",
    "            table_pos_df = table_pos_df[['Cla']]\n",
    "            table_pos_df['Cla'] = table_pos_df['Cla'].apply(to_int)\n",
    "        except:\n",
    "            print(\"no Position data found under tab GRID2\")\n",
    "\n",
    "        table_df = pd.concat([table_pos_df, table_time_df], axis=1)\n",
    "        # continue\n",
    "    \n",
    "    table_df.rename(columns = {'Cla': \"qualifying_position\", 'Time':\"qualifying_time\"}, inplace = True)\n",
    "    df = pd.concat([name_df, table_df], axis=1)\n",
    "    df['season'] = season\n",
    "    df['round'] = round\n",
    "    display(table_df)\n",
    "    # df['qp_url'] = qp_url\n",
    "    # display(df)\n",
    "    if race.empty:\n",
    "        race = df\n",
    "    else:\n",
    "        race = pd.merge(race, df, how='outer', on=['season', 'round', 'driver_name'])\n",
    "except:\n",
    "    print(\"no data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This scraper has deprecated or we may have been denied access. Do not run this snippet of code or it will purge our existing qualifying_results.csv \n",
    "# constructor_standings = pd.read_csv(\"./data/constructor_standings.csv\")\n",
    "# # ==========\n",
    "# # Qualifying Results\n",
    "# # ==========\n",
    "# from bs4 import BeautifulSoup\n",
    "# def time_to_milliseconds(time_str):\n",
    "#     milliseconds = np.nan\n",
    "#     try:\n",
    "#         parts = time_str.split(':')\n",
    "#         milliseconds = 0\n",
    "#         if len(parts) == 3:\n",
    "#             # Format is hours:minutes:seconds.milliseconds\n",
    "#             hours, minutes, seconds = parts\n",
    "#             milliseconds += int(hours) * 3600000  # Convert hours to milliseconds\n",
    "#             milliseconds += int(minutes) * 60000  # Convert minutes to milliseconds\n",
    "#         elif len(parts) == 2:\n",
    "#             # Format is minutes:seconds.milliseconds\n",
    "#             minutes, seconds = parts\n",
    "#             milliseconds += int(minutes) * 60000  # Convert minutes to milliseconds\n",
    "#         else:\n",
    "#             raise ValueError(\"Invalid time format\")\n",
    "#         # Splitting seconds and milliseconds and converting\n",
    "#         seconds, msec = seconds.split('.')\n",
    "#         milliseconds += int(seconds) * 1000  # Convert seconds to milliseconds\n",
    "#         milliseconds += int(msec)  # Add milliseconds\n",
    "#     except:\n",
    "#         print(\"time to milli error\")\n",
    "#     return milliseconds\n",
    "\n",
    "# def reformat_name(name):\n",
    "#     name = name.replace(\"-\", \" \")\n",
    "#     name = name.lower()\n",
    "#     return name\n",
    "\n",
    "# qualifying_results = pd.DataFrame()\n",
    "# # Qualifying times are only available from 1983\n",
    "# for year in list(range(2021,2022)):\n",
    "#     url = 'https://www.formula1.com/en/results.html/{}/races.html'\n",
    "#     r = requests.get(url.format(year))\n",
    "#     soup = BeautifulSoup(r.text, 'html.parser')\n",
    "#     # find links to all circuits for a certain year\n",
    "#     year_links = []\n",
    "#     for page in soup.find_all('a', attrs = {'class':\"resultsarchive-filter-item-link FilterTrigger\"}):\n",
    "#         link = page.get('href')\n",
    "#         if f'/en/results.html/{year}/races/' in link: \n",
    "#             year_links.append(link)\n",
    "#     # for each circuit, switch to the starting grid page and read table\n",
    "#     year_df = pd.DataFrame()\n",
    "#     new_url = 'https://www.formula1.com{}'\n",
    "#     for n, link in list(enumerate(year_links)):\n",
    "#         link = link.replace('race-result.html', 'starting-grid.html')\n",
    "#         print(f\"{year}, {n+1}\")\n",
    "#         print(f\"https://www.formula1.com{link}\")\n",
    "#         try:\n",
    "#             df = pd.read_html(new_url.format(link))\n",
    "#         except:\n",
    "#             print(\"data not yet available\")\n",
    "#             continue\n",
    "#         df = df[0]\n",
    "#         display(df)\n",
    "#         df['season'] = year\n",
    "#         df['round'] = n+1\n",
    "#         for col in df:\n",
    "#             if 'Unnamed' in col:\n",
    "#                 df.drop(col, axis = 1, inplace = True)\n",
    "#         year_df = pd.concat([year_df, df])\n",
    "#     # concatenate all tables from all years  \n",
    "#     qualifying_results = pd.concat([qualifying_results, year_df])\n",
    "# # rename columns\n",
    "# qualifying_results.rename(columns = {'Pos': 'grid', 'Driver': 'driver_name', 'Car': 'car',\n",
    "#                                      'Time': 'qualifying_time'}, inplace = True)\n",
    "# # drop driver number column\n",
    "# # qualifying_results.drop(['No', 'Gap', 'Laps'], axis = 1, inplace = True)\n",
    "# qualifying_results.drop(['No'], axis = 1, inplace = True)\n",
    "# qualifying_results['driver_name'] = qualifying_results['driver_name'].str.split().apply(lambda x: ' '.join(x[:-1]))\n",
    "# qualifying_results['driver_name'] = qualifying_results['driver_name'].apply(reformat_name)\n",
    "# qualifying_results['qualifying_time'] = qualifying_results['qualifying_time'].apply(time_to_milliseconds)\n",
    "# qualifying_results.to_csv(\"./data/qualifying_results.csv\", sep=\",\", index=False)\n",
    "# display(qualifying_results)\n",
    "# for row in qualifying_results.itertuples():\n",
    "#     print(f\"{row.season}, {row.round}, {row.qualifying_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "573",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
